{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_EN9Fy-4FnM"
      },
      "source": [
        "# Hyperparameter Tuning\n",
        "\n",
        "Scikit-learn documentation:\n",
        "* [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
        "* [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
        "* [Breast Cancer dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSVWW-R64FnQ"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/murilogustineli/hype-tuning/blob/main/gridsearch.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ_cp9Bh4FnR"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ngve-Kc04FnR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IorzjjtZ4FnS"
      },
      "source": [
        "## Part 1: Machine Learning intro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngH2uxmC4FnT"
      },
      "source": [
        "### Load data from sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rn_obzMu4FnU"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load Breast Cancer dataset from sklearn\n",
        "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
        "\n",
        "# Data dimensions\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcJ9L3ku4FnV"
      },
      "outputs": [],
      "source": [
        "# Distribution of target variable\n",
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WF-Ovrt4FnV"
      },
      "source": [
        "Dataset summary:\n",
        "1. The Breast Cancer dataset has 569 instances and 31 features\n",
        "    * Each instance has a binary target variable indicating the patientâ€™s diagnosis (malignant or benign)\n",
        "    * `Malignant` == 0\n",
        "    * `Benign` == 1\n",
        "2. The target class distribution is **imbalanced!**\n",
        "    * 357 instances diagnosed as benign and 212 as malignant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jvdp3Azz4FnX"
      },
      "source": [
        "### Training a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwwxOyxd4FnY"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# KNN model\n",
        "clf = KNeighborsClassifier()\n",
        "\n",
        "\n",
        "# Fit model\n",
        "clf.fit(X, y)\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X)\n",
        "# Scores\n",
        "score = clf.score(X, y)\n",
        "f1 = f1_score(y_pred, y)\n",
        "\n",
        "# Scores\n",
        "print(f\"{clf.__class__.__name__}\")\n",
        "print(f\"Accuracy: {round(score, 3)}\")\n",
        "print(f\"F1 Score: {round(f1, 3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axTYHGmF4FnZ"
      },
      "outputs": [],
      "source": [
        "# KNN object\n",
        "clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PX8bjlqG4FnZ"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# DecisionTree\n",
        "clf = DecisionTreeClassifier(max_depth=2)\n",
        "\n",
        "# Fit model\n",
        "clf.fit(X, y)\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X)\n",
        "# Scores\n",
        "score = clf.score(X, y)\n",
        "f1 = f1_score(y_pred, y)\n",
        "\n",
        "# Scores\n",
        "print(f\"{clf.__class__.__name__}\")\n",
        "print(f\"Accuracy: {round(score, 3)}\")\n",
        "print(f\"F1 Score: {round(f1, 3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqotn1HK4FnZ"
      },
      "outputs": [],
      "source": [
        "# Visualize Decision Tree\n",
        "feature_names = list(X.columns)\n",
        "class_names = ['Malignant', 'Benign'] # Malignant==0, Benign==1\n",
        "\n",
        "# Init plot\n",
        "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(4, 4), dpi=200)\n",
        "tree.plot_tree(\n",
        "    clf,\n",
        "    feature_names=feature_names,\n",
        "    class_names=class_names,\n",
        "    filled=True,\n",
        "    fontsize=5,\n",
        "    rounded=True);\n",
        "fig.tight_layout(pad=3);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csXfehHu4Fna"
      },
      "source": [
        "## Part 2: Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GHGjD7S4Fna"
      },
      "source": [
        "### Scaling features\n",
        "`Scaling` features is important because it can help improve the performance of the model.\n",
        "1. Scaling ensures that each feature is on a similar scale.\n",
        "2. Prevents some features from dominating others in terms of their influence on teh model.\n",
        "3. Help convergence of certain algorithms.\n",
        "4. Make the model more robust to outliers and noise in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bPcJoca4Fna"
      },
      "outputs": [],
      "source": [
        "# Rename columns to lower case\n",
        "cols = list(X.columns)\n",
        "lower_cols = [col.replace(\" \", \"_\").lower() for col in cols]\n",
        "X.columns = lower_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igutB7fd4Fnb"
      },
      "outputs": [],
      "source": [
        "# Get max from each feature\n",
        "mean_radius_max = np.max(X['mean_area'])\n",
        "mean_area_max = np.max(X['mean_smoothness'])\n",
        "\n",
        "print(f'Max mean area:   {mean_radius_max}')\n",
        "print(f'Max mean smooth: {mean_area_max}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2jb_ouM4Fnb"
      },
      "outputs": [],
      "source": [
        "# Plot different features\n",
        "def plot_scales(df, feature1, feature2):\n",
        "    fig, ax = plt.subplots(figsize=(6, 4), dpi=150)\n",
        "    ax.scatter(df[feature1], df[feature2])\n",
        "    ax.set_title('Different scales between two features')\n",
        "    ax.set_xlabel(f\"{feature1.replace('_', ' ').title()}\")\n",
        "    ax.set_ylabel(f\"{feature2.replace('_', ' ').title()}\")\n",
        "    ax.grid(color='blue', linestyle='--', linewidth=1, alpha=0.2)\n",
        "    for spine in ['top', 'right']:\n",
        "      ax.spines[spine].set_visible(False)\n",
        "    fig.tight_layout(pad=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQuZruFi4Fnb"
      },
      "outputs": [],
      "source": [
        "# Plot difference\n",
        "plot_scales(df=X, feature1='mean_area', feature2='mean_smoothness')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na5O1rmk4Fnc"
      },
      "source": [
        "### StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGChiXB14Fnc"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXxo4-NO4Fnc"
      },
      "outputs": [],
      "source": [
        "# Plot difference\n",
        "plot_scales(df=X_scaled, feature1='mean_area', feature2='mean_smoothness')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bMT78Gg4Fnd"
      },
      "source": [
        "### We have to rethink what our model actually is!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1SxMqMH4Fnd"
      },
      "source": [
        "### Creating your first pipeline\n",
        "Let's put everything into a pipeline!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DulXxENl4Fnd"
      },
      "source": [
        "### KNN pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmHFV7QU4Fnd"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# KNN pipeline\n",
        "pipe = Pipeline(steps=[\n",
        "    ('scale', StandardScaler()),\n",
        "    ('model', KNeighborsClassifier())])\n",
        "\n",
        "# Fit model\n",
        "pipe.fit(X, y)\n",
        "# Make predictions\n",
        "y_pred = pipe.predict(X)\n",
        "# Scores\n",
        "score = pipe.score(X, y)\n",
        "f1 = f1_score(y_pred, y)\n",
        "\n",
        "# Scores\n",
        "print(f\"{pipe['model'].__class__.__name__}\")\n",
        "print(f\"Accuracy: {round(score, 3)}\")\n",
        "print(f\"F1 Score: {round(f1, 3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnJq6Phn4Fnd"
      },
      "outputs": [],
      "source": [
        "# Pipeline object\n",
        "pipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3es7m-jX4Fne"
      },
      "outputs": [],
      "source": [
        "# Pipeline scaler\n",
        "pipe['scale']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-r5K4Ut4Fne"
      },
      "outputs": [],
      "source": [
        "# Pipeline model\n",
        "pipe['model']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEvUINHz4Fne"
      },
      "source": [
        "### DecisionTree pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjNoT-Uv4Fne"
      },
      "outputs": [],
      "source": [
        "# Decision Tree pipeline\n",
        "pipe = Pipeline(steps=[\n",
        "    ('scale', StandardScaler()),\n",
        "    ('model', DecisionTreeClassifier(max_depth=2))])\n",
        "\n",
        "# Fit model\n",
        "pipe.fit(X, y)\n",
        "# Make predictions\n",
        "y_pred = pipe.predict(X)\n",
        "# Scores\n",
        "score = pipe.score(X, y)\n",
        "f1 = f1_score(y_pred, y)\n",
        "\n",
        "print(f\"Accuracy: {round(score, 3)}\")\n",
        "print(f\"F1 Score: {round(f1, 3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQL7uJcU4Fne"
      },
      "outputs": [],
      "source": [
        "# Pipeline object\n",
        "pipe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y2MHS-c4Fnf"
      },
      "source": [
        "### Run different pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3958d2M4Fnf"
      },
      "outputs": [],
      "source": [
        "# Function to run pipelines\n",
        "def fit_predict(pipe: object, X: pd.DataFrame,  y: pd.DataFrame):\n",
        "    # Fit model\n",
        "    pipe.fit(X, y)\n",
        "    # Make predictions\n",
        "    y_pred = pipe.predict(X)\n",
        "    # Scores\n",
        "    score = pipe.score(X, y)\n",
        "    f1 = f1_score(y_pred, y)\n",
        "    \n",
        "    print(f\"{str(pipe['model'].__class__.__name__)}\")\n",
        "    print(f\"Accuracy: {round(score, 3)}\")\n",
        "    print(f\"F1 Score: {round(f1, 3)}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjNP_NLe4Fnf"
      },
      "outputs": [],
      "source": [
        "# KNN pipeline\n",
        "knn_pipe = Pipeline(steps=[\n",
        "    ('scale', StandardScaler()),\n",
        "    ('model', KNeighborsClassifier(n_neighbors=5))])\n",
        "\n",
        "# Decision Tree pipeline\n",
        "dt_pipe = Pipeline(steps=[\n",
        "    ('scale', StandardScaler()),\n",
        "    ('model', DecisionTreeClassifier(max_depth=2))])\n",
        "\n",
        "# Fit pipelines\n",
        "fit_predict(pipe=knn_pipe, X=X, y=y)\n",
        "fit_predict(pipe=dt_pipe, X=X, y=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wUhJWYr4Fnf"
      },
      "source": [
        "### We're making a HUGE mistake!!!\n",
        "How do we know we are able to **generalize** to new data?\n",
        "* We used the entire data for training and testing, and that's bad!!\n",
        "* We don't want to evaluate model performance on the same dataset we used to train it.\n",
        "    * **Generalization** is about the ability of a model to perform well on unseen data.\n",
        "* We need to split the data intro `training` and `testing`.\n",
        "    * Use the `training` data to fit the model and make predictions\n",
        "    * Use the `testing` data to test the model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztUoW-E04Fnf"
      },
      "source": [
        "### Train/Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hNqUMaj4Fng"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train/Test Split using Stratified Sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "print(f\"Train data: {X_train.shape, y_train.shape}\")\n",
        "print(f\"Test data:  {X_test.shape, y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1Bdpe-B4Fng"
      },
      "source": [
        "### Handle imbalanced data\n",
        "The data is also imbalanced, where one class have more instances than another class.\n",
        "* 357 instances diagnosed as `benign` and 212 as `malignant`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbTyuhPA4Fng"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# SMOTE (Synthetic Minority Oversampling Technique)\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"Train data: {X_train.shape, y_train.shape}\")\n",
        "print(f\"Test data:  {X_test.shape, y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GwCYWCB4Fng"
      },
      "outputs": [],
      "source": [
        "# Class distribution after SMOTE\n",
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPrUrhtj4Fnh"
      },
      "outputs": [],
      "source": [
        "# Test data class distribution\n",
        "y_test.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rM7SYBP4Fnh"
      },
      "source": [
        "### Preprocess data\n",
        "Putting all the steps above together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeVAtX2d4Fnh"
      },
      "outputs": [],
      "source": [
        "# Preprocess data\n",
        "def preprocess_data(test_size=0.2, oversample=False) -> tuple:\n",
        "    # Load dataset\n",
        "    X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
        "\n",
        "    # Train/Test Split using Stratified Sampling\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, stratify=y, random_state=42)\n",
        "\n",
        "    # Oversampling using SMOTE\n",
        "    if oversample:\n",
        "        sm = SMOTE(random_state=42)\n",
        "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBtyXsLu4Fnh"
      },
      "outputs": [],
      "source": [
        "# Get data\n",
        "X_train, X_test, y_train, y_test = preprocess_data(test_size=0.2, oversample=True)\n",
        "\n",
        "print(f\"Train data: {X_train.shape, y_train.shape}\")\n",
        "print(f\"Test data:  {X_test.shape, y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PV876D264Fni"
      },
      "outputs": [],
      "source": [
        "# KNN pipeline\n",
        "knn_pipe = Pipeline(steps=[\n",
        "    ('scale', StandardScaler()),\n",
        "    ('model', KNeighborsClassifier())])\n",
        "\n",
        "# Decision Tree pipeline\n",
        "dt_pipe = Pipeline(steps=[\n",
        "    ('scale', StandardScaler()),\n",
        "    ('model', DecisionTreeClassifier(max_depth=1))])\n",
        "\n",
        "# Fit pipelines\n",
        "fit_predict(pipe=knn_pipe, X=X, y=y)\n",
        "fit_predict(pipe=dt_pipe, X=X, y=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDOl0wGu4Fni"
      },
      "source": [
        "## Part 3: GridSearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONe2l04D4Fni"
      },
      "source": [
        "* `GridSearch` is a technique used to find the optimal hyperparameters for a machine learning model.\n",
        "* `Hyperparameters` are certain values or weights that determine the learning process of an algorithm..\n",
        "* `Hyperparameter tuning` is the process of finding the best hyperparameters for a given machine learning algorithm and dataset.\n",
        "    * The performance of a machine learning model is highly dependent on the values of its hyperparameters.\n",
        "    * Choosing the right hyperparameters is critical for achieving good performance.\n",
        "* `Stratified Sampling` ensures the population is divided into homogeneous subgroups where the right amount of instances is sampled from each class\n",
        "    * Guarantees that the test set is representative of the overall population\n",
        "\n",
        "**Scikit-learn documentation:**\n",
        "* [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
        "* [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
        "* [`KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ohwvr9JU4Fni"
      },
      "outputs": [],
      "source": [
        "# Looking at DecisionTree parameters\n",
        "dt_pipe['model'].get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQxtGexC4Fni"
      },
      "source": [
        "### GridSearch for DecisionTree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Io9oKVvJ4Fni"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "\n",
        "# Decision Tree pipeline\n",
        "dt_pipe = Pipeline(steps=[\n",
        "    ('scale', StandardScaler()),\n",
        "    ('model', DecisionTreeClassifier())])\n",
        "\n",
        "# DecisionTree GridSearchCV params\n",
        "dt_param_grid = {\n",
        "    'model__criterion': ['gini', 'entropy'],\n",
        "    'model__max_depth': list(range(1, 11, 1)),\n",
        "    'model__min_samples_leaf': list(range(1, 11, 1))}\n",
        "\n",
        "# Stratified sampling\n",
        "strat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Init GridSearchCV\n",
        "gridsearch = GridSearchCV(\n",
        "    estimator=dt_pipe,\n",
        "    param_grid=dt_param_grid,\n",
        "    scoring='f1',\n",
        "    cv=strat_kfold,\n",
        "    verbose=2,\n",
        "    n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CElD33Zz4Fnj"
      },
      "outputs": [],
      "source": [
        "# Fit model\n",
        "dt_clf = gridsearch.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNmtzNoR4Fnj"
      },
      "source": [
        "#### Why 200 candidates? Why 1,000 fits?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwdvfuVa4Fnj"
      },
      "outputs": [],
      "source": [
        "criterion = ['gini', 'entropy']\n",
        "max_depth = list(range(1, 11, 1))\n",
        "min_samples_leaf = list(range(1, 11, 1))\n",
        "n_splits = 5\n",
        "\n",
        "candidates = len(criterion) * len(max_depth) * len(min_samples_leaf)\n",
        "print(f'Candidates: {candidates}')\n",
        "print(f'Total fits: {candidates*n_splits}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3y5dD2Q54Fnj"
      },
      "outputs": [],
      "source": [
        "# Look at GridSearch object\n",
        "dt_clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ng30An5Z4Fnk"
      },
      "outputs": [],
      "source": [
        "# Best estimator\n",
        "dt_clf.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFvaIQ5A4Fnk"
      },
      "outputs": [],
      "source": [
        "# Best parameters\n",
        "dt_clf.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jF2fesu4Fnk"
      },
      "source": [
        "### Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DkjOMUJ4Fnk"
      },
      "outputs": [],
      "source": [
        "# Train and test scores\n",
        "train_score = dt_clf.score(X_train, y_train)\n",
        "test_score = dt_clf.score(X_test, y_test)\n",
        "\n",
        "print(f'Train score: {round(train_score, 3)}')\n",
        "print(f'Test score:  {round(test_score, 3)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSZ5h-4Z4Fnk"
      },
      "outputs": [],
      "source": [
        "# F1 score\n",
        "y_pred = dt_clf.predict(X_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f'F1 score: {round(f1, 3)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXAyPJuo4Fnk"
      },
      "source": [
        "### Performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9YCaMZS4Fnl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# Display scores\n",
        "model_name = dt_clf.best_estimator_['model'].__class__.__name__\n",
        "print(f\"{dt_clf.__class__.__name__}:\\t {model_name}\")\n",
        "print(f\"Train score:     {round(train_score, 3)}\")\n",
        "print(f\"Test score:      {round(test_score, 3)}\")\n",
        "print(f\"Accuracy score:  {round(accuracy, 3)}\")\n",
        "print(f\"Precision score: {round(precision, 3)}\")\n",
        "print(f\"Recall score:    {round(recall, 3)}\")\n",
        "print(f\"F1 score:        {round(f1, 3)}\")\n",
        "print(f\"ROC AUC score:   {round(roc_auc, 3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_3AgpYj4Fnl"
      },
      "outputs": [],
      "source": [
        "# Look at GridSearchCV results\n",
        "df = pd.DataFrame(gridsearch.cv_results_)\n",
        "df.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzxIsKV04Fnl"
      },
      "source": [
        "### GridSearch for KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waunlVuS4Fnl"
      },
      "outputs": [],
      "source": [
        "# KNN pipeline\n",
        "knn_pipe = Pipeline(steps=[\n",
        "    ('scale', StandardScaler()),\n",
        "    ('model', KNeighborsClassifier())])\n",
        "\n",
        "# KNN GridSearchCV params\n",
        "knn_param_grid = {\n",
        "    'model__n_neighbors': list(range(5, 55, 5)),\n",
        "    'model__weights' : ['uniform', 'distance'],\n",
        "    'model__metric': ['euclidean', 'manhattan']}\n",
        "\n",
        "# Stratified sampling\n",
        "strat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Init GridSearchCV\n",
        "gridsearch = GridSearchCV(\n",
        "    estimator=knn_pipe,\n",
        "    param_grid=knn_param_grid,\n",
        "    scoring='f1',\n",
        "    cv=strat_kfold,\n",
        "    verbose=2,\n",
        "    n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "armqAD494Fnm"
      },
      "outputs": [],
      "source": [
        "# Fit model\n",
        "knn_clf = gridsearch.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrKuocDs4Fnm"
      },
      "outputs": [],
      "source": [
        "knn_clf.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZfdZs0S4Fnm"
      },
      "outputs": [],
      "source": [
        "# Metrics\n",
        "train_score = dt_clf.score(X_train, y_train)\n",
        "test_score = dt_clf.score(X_test, y_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# Display scores\n",
        "model_name = knn_clf.best_estimator_['model'].__class__.__name__\n",
        "print(f\"{knn_clf.__class__.__name__}:\\t {model_name}\")\n",
        "print(f\"Train score:     {round(train_score, 3)}\")\n",
        "print(f\"Test score:      {round(test_score, 3)}\")\n",
        "print(f\"Accuracy score:  {round(accuracy, 3)}\")\n",
        "print(f\"Precision score: {round(precision, 3)}\")\n",
        "print(f\"Recall score:    {round(recall, 3)}\")\n",
        "print(f\"F1 score:        {round(f1, 3)}\")\n",
        "print(f\"ROC AUC score:   {round(roc_auc, 3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UknGHng54Fnm"
      },
      "source": [
        "## Part 4: Going deeper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFqF0S-94Fnn"
      },
      "source": [
        "> _\"Implementing machine learning is first and foremost a software endeavour, and requires experience building well architected, reliable, easy to deploy software.\"_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyV9Kch64Fnn"
      },
      "source": [
        "### Learner Class\n",
        "Each model has its own pipeline and gridsearch parameters.\n",
        "\n",
        "**Documentation:**\n",
        "* [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
        "* [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
        "* [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
        "* [`KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
        "* [`XGBClassifier`](https://xgboost.readthedocs.io/en/stable/parameter.html)\n",
        "* [`MLPClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1QAohzi4Fnn"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import make_scorer, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_yjnkWX4Fnn"
      },
      "outputs": [],
      "source": [
        "# Learner class\n",
        "class Learner:\n",
        "    def __init__(self, pipe, params):\n",
        "        self.pipe = pipe\n",
        "        self.params = params\n",
        "        self.clf = None\n",
        "        self.scores = None\n",
        "        self.search_name = None\n",
        "        self.class_report = None\n",
        "        self.dataset_name = None\n",
        "        self.learning_curve = {}\n",
        "        self.validation_curve = {}\n",
        "        self.cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "        self.name = str(self.pipe['model'].__class__.__name__)\n",
        "        \n",
        "    def fit_gridsearch(self, search_func, X_train, y_train, verbose=False):\n",
        "        np.random.seed(42)\n",
        "\n",
        "        # Train learner\n",
        "        self.clf = search_func(\n",
        "            self.pipe,\n",
        "            self.params,\n",
        "            scoring={\n",
        "                'accuracy': make_scorer(accuracy_score),\n",
        "                'precision': make_scorer(precision_score),\n",
        "                'recall': make_scorer(recall_score),\n",
        "                'f1': make_scorer(f1_score),\n",
        "                'roc_auc': make_scorer(roc_auc_score)},\n",
        "            refit='f1',\n",
        "            cv=self.cv,\n",
        "            verbose=verbose,\n",
        "            n_jobs=-1)\n",
        "        # Fit the model\n",
        "        self.clf.fit(X_train, y_train)\n",
        "        self.search_name = str(self.clf.__class__.__name__)\n",
        "\n",
        "    def get_scores(self, X_train, X_test, y_train, y_test):\n",
        "        if self.search_name == 'Benchmark':\n",
        "            best_estimator = self.clf\n",
        "        else:\n",
        "            best_estimator = self.clf.best_estimator_\n",
        "        \n",
        "        np.random.seed(42)\n",
        "        # Score on training data\n",
        "        start_time = time.time()\n",
        "        best_estimator.fit(X_train ,y_train)\n",
        "        end_time = time.time()\n",
        "        wall_clock_fit = end_time - start_time\n",
        "        # train_score = self.clf.score(X_train, y_train)\n",
        "        train_score = best_estimator.score(X_train, y_train)\n",
        "\n",
        "        # Score on test data\n",
        "        start_time = time.time()\n",
        "        # y_pred = self.clf.predict(X_test)\n",
        "        y_pred = best_estimator.predict(X_test)\n",
        "        end_time = time.time()\n",
        "        wall_clock_pred = end_time - start_time\n",
        "        # test_score = self.clf.score(X_test, y_test)\n",
        "        test_score = best_estimator.score(X_test, y_test)\n",
        "        # Metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        roc_auc = roc_auc_score(y_test, y_pred)\n",
        "        # Classification report\n",
        "        self.class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "        self.scores = {\n",
        "            'train_score': round(train_score, 3),\n",
        "            'test_score': round(test_score, 3),\n",
        "            'accuracy': round(accuracy, 3),\n",
        "            'precision': round(precision, 3),\n",
        "            'recall': round(recall, 3),\n",
        "            'f1': round(f1, 3),\n",
        "            'roc_auc': round(roc_auc, 3),\n",
        "            'wall_clock_fit': wall_clock_fit,\n",
        "            'wall_clock_pred': wall_clock_pred}\n",
        "\n",
        "    # Evaluate Learner class\n",
        "    def evaluate_learner(self):\n",
        "        print(f\"{'#################################'*2}\")\n",
        "        print(f'{self.search_name}:\\t  {self.name}')\n",
        "        print(f\"Train score:     {round(self.scores['train_score'], 3)}\")\n",
        "        print(f\"Test score:      {round(self.scores['test_score'], 3)}\")\n",
        "        print(f\"Accuracy score:  {round(self.scores['accuracy'], 3)}\")\n",
        "        print(f\"Precision score: {round(self.scores['precision'], 3)}\")\n",
        "        print(f\"Recall score:    {round(self.scores['recall'], 3)}\")\n",
        "        print(f\"F1 score:        {round(self.scores['f1'], 3)}\")\n",
        "        print(f\"ROC AUC score:   {round(self.scores['roc_auc'], 3)}\")\n",
        "        print(f\"Wall Clock Fit:  {round(self.scores['wall_clock_fit'], 3)}\")\n",
        "        print(f\"Wall Clock Pred: {round(self.scores['wall_clock_pred'], 3)}\")\n",
        "        # Classification report\n",
        "        print(f\"\\nClassification report:\\n{self.class_report}\")\n",
        "        \n",
        "        # Best score and best params\n",
        "        print(f\"Best score: {round(self.clf.best_score_, 3)}\")\n",
        "        print(\"Best params:\")\n",
        "        for param in self.clf.best_params_.items():\n",
        "            print(f\"\\t{param}\")\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lNwVH9O4Fno"
      },
      "source": [
        "### Pipe setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47R7wyY64Fnp"
      },
      "outputs": [],
      "source": [
        "def learner_setup():\n",
        "    # KNN pipeline\n",
        "    knn_pipe = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', KNeighborsClassifier())])\n",
        "    # GridSearchCV params\n",
        "    knn_param_grid = {\n",
        "        'model__n_neighbors': list(range(1, 9, 1)),\n",
        "        'model__weights' : ['uniform', 'distance'],\n",
        "        'model__metric': ['euclidean', 'manhattan']}\n",
        "\n",
        "\n",
        "    # Decision Tree pipeline\n",
        "    dt_pipe = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', DecisionTreeClassifier(random_state=42))])\n",
        "    # GridSearchCV params\n",
        "    dt_param_grid = {\n",
        "        'model__criterion': ['gini', 'entropy'],\n",
        "        'model__max_depth': range(1, 8, 1),\n",
        "        'model__min_samples_leaf': range(1, 6, 1)}\n",
        "\n",
        "\n",
        "    # XGBoost pipeline\n",
        "    xgb_pipe = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', XGBClassifier(seed=42))])\n",
        "    # GridSearchCV params\n",
        "    xgb_param_grid = {\n",
        "        'model__objective': ['binary:logistic'],\n",
        "        'model__n_estimators': np.arange(100, 300, 50),\n",
        "        'model__learning_rate': np.arange(0.1, 0.2, 0.05),\n",
        "        'model__max_depth': [3, 4, 5, 6],\n",
        "        'model__min_child_weight': np.arange(1, 5, 1),\n",
        "        'model__subsample': np.arange(0.6, 1.0, 0.1),\n",
        "        'model__colsample_bytree': np.arange(0.6, 1.0, 0.1)}\n",
        "\n",
        "    # MLP pipeline\n",
        "    mlp_pipe = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', MLPClassifier(random_state=42))])\n",
        "    # GridSearchCV params\n",
        "    mlp_param_grid = {\n",
        "        'model__activation': ['relu', 'tanh', 'logistic'],\n",
        "        'model__max_iter': [1000],\n",
        "        'model__hidden_layer_sizes': [(2,),(4,),(8,),(16,),(32,),(64,)],\n",
        "        'model__learning_rate': ['constant', 'adaptive'],\n",
        "        'model__learning_rate_init': [0.001, 0.01, 0.1, 1]}\n",
        "\n",
        "\n",
        "    # Init learners\n",
        "    knn_grid = Learner(pipe=knn_pipe, params=knn_param_grid)\n",
        "    dt_grid = Learner(pipe=dt_pipe, params=dt_param_grid)\n",
        "    xgb_grid = Learner(pipe=xgb_pipe, params=xgb_param_grid)\n",
        "    mlp_grid = Learner(pipe=mlp_pipe, params=mlp_param_grid)\n",
        "\n",
        "    # List of learners\n",
        "    learners = [\n",
        "        knn_grid,\n",
        "        dt_grid,\n",
        "        xgb_grid,\n",
        "        mlp_grid\n",
        "    ]\n",
        "\n",
        "    return learners"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLq-UNxk4Fnp"
      },
      "source": [
        "### Train Learners using `RandomizedSearchCV`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrPiiJMD4Fnp"
      },
      "outputs": [],
      "source": [
        "# Setup learners\n",
        "learners = learner_setup()\n",
        "\n",
        "# Fit learners\n",
        "with tqdm(learners, unit='batch') as tepoch:\n",
        "    for learner in tepoch:\n",
        "        tepoch.set_description(\"Training progress\")   \n",
        "        # Fit GridSearchCV and get scores\n",
        "        learner.fit_gridsearch(RandomizedSearchCV, X_train, y_train)\n",
        "        learner.get_scores(X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l128myF74Fnq"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8WUfCWa4Fnq"
      },
      "outputs": [],
      "source": [
        "# Evaluate learner performance\n",
        "for learner in learners:\n",
        "    learner.evaluate_learner()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Lhrtysb4Fnq"
      },
      "outputs": [],
      "source": [
        "# Trained learners\n",
        "knn, dt, xgb, mlp = learners"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hax-L14w4Fnq"
      },
      "outputs": [],
      "source": [
        "# KNN best estimator\n",
        "knn.clf.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2ifsvXC4Fnq"
      },
      "outputs": [],
      "source": [
        "# DecisionTree best estimator\n",
        "dt.clf.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTvNcHlI4Fnr"
      },
      "outputs": [],
      "source": [
        "# XGBoost best estimator\n",
        "xgb.clf.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3WOH5Y94Fnr"
      },
      "outputs": [],
      "source": [
        "# MLPClassifier best estimator\n",
        "mlp.clf.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1MPViwg4Fnr"
      },
      "source": [
        "### Comparing Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDpjKinA4Fnr"
      },
      "outputs": [],
      "source": [
        "# Function to run pipelines\n",
        "def fit_predict(pipe, X_train, X_test, y_train, y_test):\n",
        "    # Fit model\n",
        "    pipe.fit(X_train, y_train)\n",
        "    # Make predictions\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    # Scores\n",
        "    score = pipe.score(X_test, y_test)\n",
        "    f1 = f1_score(y_pred, y_test)\n",
        "    \n",
        "    # Print results\n",
        "    print(f\"{str(pipe['model'].__class__.__name__)}\")\n",
        "    print(f\"Accuracy: {round(score, 3)}\")\n",
        "    print(f\"F1 Score: {round(f1, 3)}\\n\")\n",
        "\n",
        "    return round(f1, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMePH3e-4Fns"
      },
      "source": [
        "### Without tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rRVKm2J4Fns"
      },
      "outputs": [],
      "source": [
        "# KNN pipeline\n",
        "knn_pipe = Pipeline(steps=[\n",
        "    ('scale', StandardScaler()),\n",
        "    ('model', KNeighborsClassifier(n_neighbors=20))])\n",
        "\n",
        "# Decision Tree pipeline\n",
        "dt_pipe = Pipeline(steps=[\n",
        "    ('scale', StandardScaler()),\n",
        "    ('model', DecisionTreeClassifier(max_depth=1, random_state=42))])\n",
        "\n",
        "# XGBoost pipeline\n",
        "xgb_pipe = Pipeline(steps=[\n",
        "    ('scale', StandardScaler()),\n",
        "    ('model', XGBClassifier(max_depth=1, seed=42))])\n",
        "\n",
        "# Pipe setup\n",
        "mlp_pipe = Pipeline(steps=[\n",
        "    ('scale', StandardScaler()),\n",
        "    ('model', MLPClassifier(\n",
        "        hidden_layer_sizes=(10,10,), max_iter=1000, random_state=42))])\n",
        "\n",
        "# Fit pipelines\n",
        "knn_f1 = fit_predict(knn_pipe, X_train, X_test, y_train, y_test)\n",
        "dt_f1 = fit_predict(dt_pipe, X_train, X_test, y_train, y_test)\n",
        "xgb_f1 = fit_predict(xgb_pipe, X_train, X_test, y_train, y_test)\n",
        "mlp_f1 = fit_predict(mlp_pipe, X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZExZbZ8M4Fns"
      },
      "source": [
        "### Tuned hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k-EGUdW4Fns"
      },
      "outputs": [],
      "source": [
        "def tuned_setup():\n",
        "    # KNN pipeline\n",
        "    knn_pipe = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', KNeighborsClassifier())])\n",
        "        \n",
        "    knn_tuned_params = {\n",
        "        'model__weights': ['distance'],\n",
        "\t\t'model__n_neighbors': [7],\n",
        "\t\t'model__metric': ['manhattan']}\n",
        "\n",
        "    # Decision Tree pipeline\n",
        "    dt_pipe = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', DecisionTreeClassifier(random_state=42))])\n",
        "    \n",
        "    dt_tuned_params = {\n",
        "\t\t'model__min_samples_leaf': [3],\n",
        "\t\t'model__max_depth': [5],\n",
        "\t\t'model__criterion': ['gini']}\n",
        "    \n",
        "\t# XGBoost pipeline\n",
        "    xgb_pipe = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', XGBClassifier(seed=42))])\n",
        "        \n",
        "    xgb_tuned_params = {\n",
        "\t\t'model__subsample': [0.6],\n",
        "\t\t'model__objective': ['binary:logistic'],\n",
        "\t\t'model__n_estimators': [250],\n",
        "\t\t'model__min_child_weight': [2],\n",
        "\t\t'model__max_depth': [4],\n",
        "\t\t'model__learning_rate': [0.15],\n",
        "\t\t'model__colsample_bytree': [0.7]}\n",
        "\n",
        "    # MLP pipeline\n",
        "    mlp_pipe = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', MLPClassifier(random_state=42))])\n",
        "        \n",
        "    mlp_tuned_params = {\n",
        "\t\t'model__max_iter': [1000],\n",
        "\t\t'model__learning_rate_init': [0.001],\n",
        "\t\t'model__learning_rate': ['constant'],\n",
        "\t\t'model__hidden_layer_sizes': [(3,)],\n",
        "\t\t'model__activation': ['relu']}\n",
        "\n",
        "    # Init learners\n",
        "    knn_grid = Learner(pipe=knn_pipe, params=knn_tuned_params)\n",
        "    dt_grid = Learner(pipe=dt_pipe, params=dt_tuned_params)\n",
        "    xgb_grid = Learner(pipe=xgb_pipe, params=xgb_tuned_params)\n",
        "    mlp_grid = Learner(pipe=mlp_pipe, params=mlp_tuned_params)\n",
        "\n",
        "    # List of learners\n",
        "    learners = [\n",
        "        knn_grid,\n",
        "        dt_grid,\n",
        "        xgb_grid,\n",
        "        mlp_grid\n",
        "    ]\n",
        "\n",
        "    return learners"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrS3OpWp4Fns"
      },
      "source": [
        "### Train tuned learners"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSG6z3V_4Fnt"
      },
      "outputs": [],
      "source": [
        "# Setup learners\n",
        "learners = tuned_setup()\n",
        "\n",
        "# Fit learners\n",
        "with tqdm(learners, unit='batch') as tepoch:\n",
        "    for learner in tepoch:\n",
        "        tepoch.set_description(\"Training progress\")   \n",
        "        # Fit GridSearchCV and get scores\n",
        "        learner.fit_gridsearch(GridSearchCV, X_train, y_train)\n",
        "        learner.get_scores(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Trained learners\n",
        "knn, dt, xgb, mlp = learners"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBWQpJRb4Fnt"
      },
      "outputs": [],
      "source": [
        "# KNN GridSearchCV results\n",
        "print(knn.name)\n",
        "print(f\"Accuracy: {knn.scores['accuracy']}\")\n",
        "print(f\"F1 Score: {knn.scores['f1']}\\n\")\n",
        "\n",
        "# DecisionTree GridSearchCV results\n",
        "print(dt.name)\n",
        "print(f\"Accuracy: {dt.scores['accuracy']}\")\n",
        "print(f\"F1 Score: {dt.scores['f1']}\\n\")\n",
        "\n",
        "# XGBoost GridSearchCV results\n",
        "print(xgb.name)\n",
        "print(f\"Accuracy: {xgb.scores['accuracy']}\")\n",
        "print(f\"F1 Score: {xgb.scores['f1']}\\n\")\n",
        "\n",
        "# MLP GridSearchCV results\n",
        "print(mlp.name)\n",
        "print(f\"Accuracy: {mlp.scores['accuracy']}\")\n",
        "print(f\"F1 Score: {mlp.scores['f1']}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_1SaJt-4Fnt"
      },
      "source": [
        "### Performance Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3NGZj-04Fnt"
      },
      "outputs": [],
      "source": [
        "# Plot final results\n",
        "def plot_model_results(no_search, grid_search):\n",
        "    fig, ax = plt.subplots(figsize=(6.4, 4.8), dpi=200)\n",
        "    ax.margins(x=0.1, y=0.1)  # No margins on x and y-axis\n",
        "    ymin = np.min((no_search, grid_search))\n",
        "    # Learner names\n",
        "    short_names = ['KNeighbors', 'DecisionTree', 'XGBoost', 'MLPClassifier']\n",
        "    models = ['KNN', 'DecisionTree', 'XGBoost', 'MLPClassifier']\n",
        "    for i in range(len(models)):\n",
        "        x = np.arange(len(models))\n",
        "        width = 0.35\n",
        "        ax.bar(x[i] - width/2, no_search[i], width=width, color='tab:blue')\n",
        "        ax.bar(x[i] + width/2, grid_search[i], width=width, color='tab:orange')\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels(short_names)\n",
        "        ax.annotate(f'{no_search[i]}', xy=(x[i] - width/2, no_search[i]),\n",
        "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
        "        ax.annotate(f'{grid_search[i]}', xy=(x[i] + width/2, grid_search[i]),\n",
        "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
        "    ax.set_title(f'Overall Performance', weight='bold', fontsize=16)\n",
        "    ax.set_xlabel('Learning Algorithms')\n",
        "    ax.set_ylabel('Test Set F1 Score')\n",
        "    ax.grid(color='blue', linestyle='--', linewidth=1, alpha=0.2)\n",
        "    ax.legend(['Without Tuning', 'GridSearch'], loc='upper left', fontsize=8)\n",
        "    for spine in ['top', 'right', 'bottom', 'left']:\n",
        "        ax.spines[spine].set_visible(False)\n",
        "    ax.set_ylim([ymin-10, 100])\n",
        "    fig.tight_layout()\n",
        "    # plt.savefig(f'./plots/PerformanceSummary.png')\n",
        "    plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zR90f0cj4Fnu"
      },
      "outputs": [],
      "source": [
        "# Without tuning\n",
        "no_search = np.round(np.multiply([knn_f1, dt_f1, xgb_f1, mlp_f1], 100), 3)\n",
        "# GridSearchCV\n",
        "grid_search = np.round(np.multiply([\n",
        "    knn.scores['f1'],\n",
        "    dt.scores['f1'],\n",
        "    xgb.scores['f1'],\n",
        "    mlp.scores['f1']], 100), 3)\n",
        "\n",
        "# Plot results\n",
        "plot_model_results(no_search, grid_search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUV9Ildm4Fnu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pYy5ZMF4Fnu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "57f1e8b789c2562e3faa8bd4fbf1bf03f323f206cff4185df1184c5825a46e3f"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}